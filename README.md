# Applied-Machine-Learning

This project performs Topic Modeling using Latent Dirichlet Allocation and Non Negative Matrix Factorization. To ensure that all the visualizations run correctly, run the notebook locally using Jupyter Notebook or on Google Colab. 

Topic modeling is a type of statistical modeling that is used to discover abstract "topics" in a collection of texts.
Latent Dirichlet Allocation (LDA) is a popular topic modeling technique to extract topics from a given corpus.  It builds a topic per document model and words per topic model, modeled as Dirichlet distributions.
NMF breaks down high-dimensional vectors into lower-dimensional vectors. As these lower-dimensional vectors are positive,Â so are their coefficients.

My primary reason for working on this project is to use Natural Language Processing Techniques to simplify tasks in everyday circumstances. For a long time, I have been consuming electronic news through apps. A news app that I use utilizes a brief description of everyday occurrences that users may swipe through to learn about. On some days, when I want to read a specific article, I have to sift through a number of headlines before I find what I'm looking for. An application that attracted my curiosity was one that used NLP methods with text to discover relevant information in a pile of data. The majority of techniques for machine learning require structured and organized data. NLP enables us to work with unstructured data to uncover important insights. Typically, data is unstructured. A lot of crucial information is lost during the data refining process. Using topic modeling on textual data will aid in extracting hidden topics from enormous amounts of data. Topic modeling has various algorithms that can be employed. 
